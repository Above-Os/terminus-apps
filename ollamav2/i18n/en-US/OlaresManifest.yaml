metadata:
  title: Ollama
  description: Get up and running with large language models.

spec:
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## OVERVIEW ##
    Ollama is a user-friendly interface for running large language models (LLMs) locally. It is a valuable tool for researchers, developers, and anyone who wants to experiment with language models. With Ollama, you can easily download and run LLMs, customize and create your own, and chat with your LLMs using files on your device.

    Ollama supports a wide range of models, including:
    - Llama 3 8B
    - Llama 3 70B
    - Phi 3 Mini 3.8B
    - Phi 3 Medium 14B
    - Gemma 2 9B
    - Gemma 2 27B
    - Mistral 7B
    - Moondream 2 1.4B
    - Neural Chat 7B
    - Starling 7B
    - Code Llama 7B
    - Llama 2 Uncensored 7B
    - LLaVA 7B
    - Solar 10.7B

  upgradeDescription: |
    Upgrade Ollama version to v0.13.0

    # New models
    - DeepSeek-OCR: DeepSeek-OCR uses optical 2D mapping to compress long contexts, achieving high OCR precision with reduced vision tokens and demonstrating practical value in document processing.
    - Cogito-V2.1: instruction tuned generative models, currently the best open-weight LLM by a US company

    # What's Changed
    - DeepSeek-OCR is now supported
    - DeepSeek-V3.1 architecture is now supported in Ollama's engine
    - Fixed performance issues that arose in Ollama 0.12.11 on CUDA
    - Fixed issue where Linux install packages were missing required Vulkan libraries
    - Improved CPU and memory detection while in containers/cgroups
    - Improved VRAM information detection for AMD GPUs
    - Improved KV cache performance to no longer require defragmentation


    Full release notes:
    https://github.com/ollama/ollama/releases/tag/v0.13.0
