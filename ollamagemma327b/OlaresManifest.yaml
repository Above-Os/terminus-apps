---
olaresManifest.version: '0.10.0'
olaresManifest.type: app

metadata:
  name: ollamagemma327b
  icon: https://app.cdn.olares.com/appstore/llm/ollama/llm/gemma3-27B.png
  description: The current, most capable model that runs on a single GPU.
  appid: ollamagemma327b
  title: Gemma3 27B (Ollama)
  version: '1.1.8'
  categories:
    - AI

entrances:
  - name: ollamaclient
    port: 8080
    host: ollamaclient
    title: Gemma3 27B
    icon: https://app.cdn.olares.com/appstore/llm/ollama/llm/gemma3-27B.png
    openMethod: default
    authLevel: internal

spec:
  versionName: 'gemma3:27b-it-q4_K_M'
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## MODEL OVERVIEW ##
    Gemma is a lightweight, family of models from Google built on Gemini technology. The Gemma 3 models are multimodal—processing text and images—and feature a 128K context window with support for over 140 languages. Available in 270M, 1B, 4B, 12B, and 27B parameter sizes, they excel in tasks like question answering, summarization, and reasoning, while their compact design allows deployment on resource-limited devices.

    # Inputs and outputs
    Input:
    - Text string, such as a question, a prompt, or a document to be summarized
    - Images, normalized to 896 x 896 resolution and encoded to 256 tokens each
    - Total input context of 128K tokens for the 4B, 12B, and 27B sizes, and 32K tokens for the 1B size

    Output:
    - Generated text in response to the input, such as an answer to a question, analysis of image content, or a summary of a document
    - Total output context of 8192 tokens


    # Key features
    Image and text input: Multimodal capabilities let you input images and text to understand and analyze visual data.
    128K token context: Significantly large input context for analyzing more data and solving more complex problems.
    Function calling: Build natural language interfaces for working with programming interfaces.
    Wide language support: Work in your language or expand your AI application's language capabilities with support for over 140 languages.
    Developer friendly model sizes: Choose a model size (270M, 1B, 4B, 12B, 27B) and precision level that works best for your task and compute resources.

  developer: Google
  website: https://ai.google.dev/gemma
  sourceCode: https://huggingface.co/google/gemma-3-27b-it
  submitter: Olares
  locale:
    - en-US
    - zh-CN
  doc: https://ai.google.dev/gemma/docs/core
  license:
    - text: Gemma Terms of Use 
      url: https://ollama.com/library/gemma3:27b/blobs/dd084c7d92a3

  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  limitedCpu: 6200m
  requiredCpu: 150m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 40Gi
  requiredMemory: 4200Mi
  requiredGpu: 0
  limitedGpu: 16Gi
  {{- else }}
  requiredMemory: 64Mi
  limitedMemory: 800Mi
  requiredDisk: 50Mi
  limitedDisk: 200Mi
  requiredCpu: 10m
  limitedCpu: 800m
  {{- end }}

  supportArch:
    - amd64
    - arm64

permission:
  appData: true
  appCache: true
  userData:
    - Home/Ollama
options:
  apiTimeout: 0
  appScope:
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
    clusterScoped: true
    appRef:
      - ollamagemma327b
  {{- else }}
    clusterScoped: false
  {{- end }}
  dependencies:
    - name: olares
      version: '>=1.12.2-0'
      type: system
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  {{- else }}
    - name: ollamagemma327b
      type: application
      version: '>=1.1.3'
      mandatory: true
  {{- end }}

provider:
- name: ollamagemma327b
  entrance: ollamaclient
  paths: ["/*"]
  verbs: ["*"]