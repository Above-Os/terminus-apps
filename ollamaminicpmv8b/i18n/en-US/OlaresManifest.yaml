metadata:
  title: MiniCPM-V 8B (Ollama)
  description: A GPT-4o Level MLLM for Single Image, Multi Image and High-FPS Video Understanding on Your Phone

spec:
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## Model OVERVIEW ##
    MiniCPM-V is a series of efficient end-side multimodal LLMs (MLLMs), which accept images, videos and text as inputs and deliver high-quality text outputs. 

    MiniCPM-V 4.5 is the latest and most capable model in the MiniCPM-V series. With a total of 8B parameters, this model outperforms GPT-4o-latest, Gemini-2.0 Pro, and Qwen2.5-VL 72B in vision-language capabilities, making it the most performant on-device multimodal model in the open-source community. This version brings new features including efficient high-FPS and long video understanding (up to 96x compression rate for video tokens), controllable hybrid fast/deep thinking, strong handwritten OCR and complex table/document parsing. It also advances MiniCPM-V's popular features such as trustworthy behavior, multilingual support and end-side deployability.

    Features
    State-of-the-art Vision-Language Capability. 
    - MiniCPM-V 4.5 achieves an average score of 77.0 on OpenCompass, a comprehensive evaluation of 8 popular benchmarks

    Efficient High-FPS and Long Video Understanding. P
    - MiniCPM-V 4.5 can perceive significantly more video frames without increasing the LLM inference cost

    Controllable Hybrid Fast/Deep Thinking. 
    - MiniCPM-V 4.5 supports both fast thinking for efficient frequent usage with competitive performance, and deep thinking for more complex problem solving. 

    Strong OCR, Document Parsing and Others. 
    - Based on LLaVA-UHD architecture, MiniCPM-V 4.5 can process high-resolution images with any aspect ratio and up to 1.8 million pixels (e.g., 1344x1344), using 4x fewer visual tokens than most MLLMs.
