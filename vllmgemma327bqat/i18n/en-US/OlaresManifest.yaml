metadata:
  title: Gemma3 27B (vLLM)
  description: The current, most capable model that runs on a single GPU.

spec:
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## MODEL OVERVIEW ##
    Gemma is a lightweight, family of models from Google built on Gemini technology. The Gemma 3 models are multimodal—processing text and images—and feature a 128K context window with support for over 140 languages. Available in 270M, 1B, 4B, 12B, and 27B parameter sizes, they excel in tasks like question answering, summarization, and reasoning, while their compact design allows deployment on resource-limited devices.

    # Inputs and outputs
    Input:
    - Text string, such as a question, a prompt, or a document to be summarized
    - Images, normalized to 896 x 896 resolution and encoded to 256 tokens each
    - Total input context of 128K tokens for the 4B, 12B, and 27B sizes, and 32K tokens for the 1B size

    Output:
    - Generated text in response to the input, such as an answer to a question, analysis of image content, or a summary of a document
    - Total output context of 8192 tokens


    # Key features
    Image and text input: Multimodal capabilities let you input images and text to understand and analyze visual data.
    128K token context: Significantly large input context for analyzing more data and solving more complex problems.
    Function calling: Build natural language interfaces for working with programming interfaces.
    Wide language support: Work in your language or expand your AI application's language capabilities with support for over 140 languages.
    Developer friendly model sizes: Choose a model size (270M, 1B, 4B, 12B, 27B) and precision level that works best for your task and compute resources.
