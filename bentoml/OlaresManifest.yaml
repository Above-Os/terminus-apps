olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: bentoml
  icon: https://file.bttcdn.com/appstore/bentoml/icon.png
  description: The easiest way to serve AI apps and models
  appid: bentoml
  title: bentoml
  version: 0.0.1
  categories:
  - Productivity
entrances:
- name: test
  host: test
  port: 3010
  icon: https://file.bttcdn.com/appstore/bentoml/icon.png
  title: bentoml
  authLevel: private
spec:
  versionName: '0.17.3'
  fullDescription: |
    BentoML is a Python library for building online serving systems optimized for AI apps and model inference.

    Easily build APIs for Any AI/ML Model. Turn any model inference script into a REST API server with just a few lines of code and standard Python type hints.

    Docker Containers made simple. No more dependency hell! Manage your environments, dependencies and model versions with a simple config file. BentoML automatically generates Docker images, ensures reproducibility, and simplifies how you deploy to different environments.
    
    Maximize CPU/GPU utilization. Build high performance inference APIs leveraging built-in serving optimization features like dynamic batching, model parallelism, multi-stage pipeline and multi-model inference-graph orchestration.
    
    Fully customizable. Easily implement your own APIs or task queues, with custom business logic, model inference and multi-model composition. Supports any ML framework, modality, and inference runtime.

    Ready for Production. Develop, run and debug locally. Seamlessly deploy to production with Docker containers or BentoCloud.

  developer: BentoML
  website: https://bentoml.com/
  sourceCode: https://github.com/bentoml/bentoml
  submitter: Olares
  language:
  - en
  doc: https://docs.bentoml.com/en/latest/?_gl=1*g6xwig*_gcl_au*ODExNzY1NTcwLjE3Mzk4NDU1NTg.
  license:
  - text: Apache-2.0
    url: https://github.com/bentoml/bentoml#Apache-2.0-1-ov-file
