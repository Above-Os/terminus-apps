---
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: {{ .Release.Namespace }}
data:
  app_backend.conf: |
    upstream app_backend {
      zone app_backend 64k;
      {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
      server llama:8080 max_fails=1 fail_timeout=2s;
      server download-svc:8090 backup;
      {{- else }}
      server llama.llamacppgptoss120bgguf-{{ .Values.admin }}:8080 max_fails=1 fail_timeout=2s;
      server download-svc.llamacppgptoss120bgguf-{{ .Values.admin }}:8090 backup;
      {{- end }}
    }

    server {
      listen 8080;
      access_log /opt/bitnami/openresty/nginx/logs/access.log;
      error_log  /opt/bitnami/openresty/nginx/logs/error.log;

      location = /ping   { return 200 'pong'; }
      location = /health { return 200 'ok'; }

      location /progress {
        {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
        proxy_pass http://download-svc:8090;
        {{- else }}
        proxy_pass http://download-svc.llamacppgptoss120bgguf-{{ .Values.admin }}:8090;
        {{- end }}
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        add_header Access-Control-Allow-Origin *;
        if ($request_method = 'OPTIONS') { return 204; }
      }

      location = /backend_health {
        {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
        proxy_pass http://llama:8080/health;
        {{- else }}
        proxy_pass http://llama.llamacppgptoss120bgguf-{{ .Values.admin }}:8080/health;
        {{- end }}
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-Host $host;
      }

      location / {
        proxy_pass http://app_backend;

        proxy_connect_timeout 1s;
        proxy_read_timeout    2s;
        proxy_send_timeout    2s;

        proxy_next_upstream         error timeout http_500 http_502 http_503 http_504 non_idempotent;
        proxy_next_upstream_tries   2;
        proxy_next_upstream_timeout 3s;

        proxy_intercept_errors on;
        error_page 500 502 503 504 = @download;

        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";

        add_header Access-Control-Allow-Origin *;
        if ($request_method = 'OPTIONS') { return 204; }
      }

      location @download {
        {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
        proxy_pass http://download-svc:8090;
        {{- else }}
        proxy_pass http://download-svc.llamacppgptoss120bgguf-{{ .Values.admin }}:8090;
        {{- end }}
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        add_header Access-Control-Allow-Origin *;
      }
    }
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llamacppgptoss120bgguf
  namespace: {{ .Release.Namespace }}
  labels:
    io.kompose.service: llamacppgptoss120bgguf
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: llamacppgptoss120bgguf
  template:
    metadata:
      labels:
        io.kompose.network/chrome-default: "true"
        io.kompose.service: llamacppgptoss120bgguf
    spec:
      volumes:
        - name: nginx-config
          configMap:
            name: nginx-config
            defaultMode: 420 # 0644
            items:
              - key: app_backend.conf
                path: app_backend.conf
      containers:
        - name: nginx
          image: docker.io/aboveos/bitnami-openresty:1.25.3-2
          ports:
            - containerPort: 8080
              protocol: TCP
          resources:
            limits:
              cpu: 500m
              memory: 500Mi
            requests:
              cpu: 10m
              memory: 64Mi
          readinessProbe:
            httpGet:
              path: /ping
              port: 8080
            initialDelaySeconds: 2
            timeoutSeconds: 2
            periodSeconds: 5
            failureThreshold: 3
          livenessProbe:
            httpGet:
              path: /ping
              port: 8080
            initialDelaySeconds: 10
            timeoutSeconds: 3
            periodSeconds: 10
            failureThreshold: 3
          volumeMounts:
            - name: nginx-config
              mountPath: /opt/bitnami/openresty/nginx/conf/server_blocks/app_backend.conf
              subPath: app_backend.conf
---
apiVersion: v1
kind: Service
metadata:
  name: llamaclient
  namespace: {{ .Release.Namespace }}
spec:
  type: ClusterIP
  selector:
    io.kompose.service: llamacppgptoss120bgguf
  ports:
    - name: http
      protocol: TCP
      port: 8080
      targetPort: 8080
