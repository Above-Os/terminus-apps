olaresManifest.version: '0.8.1'
olaresManifest.type: app
metadata:
  name: unsloth
  icon: https://file.bttcdn.com/appstore/unsloth/icon.png
  description: Finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory!
  appid: unsloth
  title: unsloth
  version: 0.0.1
  categories:
  - Productivity
entrances:
- name: test
  host: test
  port: 3010
  icon: https://file.bttcdn.com/appstore/unsloth/icon.png
  title: unsloth
  authLevel: private
spec:
  versionName: '0.17.3'
  fullDescription: |
    Unsloth makes finetuning large language models like Llama-3, Mistral, Phi-4 and Gemma 2x faster, use 70% less memory, and with no degradation in accuracy!
    
    Key Features
    - All kernels written in OpenAI's Triton language. Manual backprop engine.
    - 0% loss in accuracy - no approximation methods - all exact.
    - No change of hardware. Supports NVIDIA GPUs since 2018+. Minimum CUDA Capability 7.0 (V100, T4, Titan V, RTX 20, 30, 40x,   A100, H100, L40 etc)! GTX 1070, 1080 works, but is slow.
    - Works on Linux and Windows via WSL.
    - Supports 4bit and 16bit QLoRA / LoRA finetuning via bitsandbytes.
    - Open source trains 5x faster - see Unsloth Pro for up to 30x faster training!

  developer: unsloth
  website: https://unsloth.ai/
  sourceCode: https://github.com/unslothai/unsloth
  submitter: Olares
  language:
  - en
  doc: https://docs.unsloth.ai/
  license:
  - text: Apache-2.0
    url: https://github.com/unsloth/unsloth#Apache-2.0-1-ov-file
