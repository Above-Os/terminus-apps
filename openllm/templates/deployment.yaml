
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    io.kompose.service: openllm
  name: openllm
  namespace: {{ .Release.Namespace }}
spec:
  replicas: 1
  selector:
    matchLabels:
      io.kompose.service: openllm
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        io.kompose.network/chrome-default: "true"
        io.kompose.service: openllm
    spec:
      containers:
        - env:
            - name: PGID
              value: "1000"
            - name: PUID
              value: "1000"
            - name: TZ
              value: Etc/UTC
          image: "ghcr.io/bentoml/openllm:0.3.6"
          args: ['start','opt','--model-id','facebook/opt-2.7b']
          name: openllm
          ports:

            - containerPort: 3000
                    
          resources: {}

          volumeMounts:
                    
            - mountPath: /appdata
              name: appdata
                      
            - mountPath: /userdata
              name: userdata
      
        - env:
            - name: PGID
              value: "1000"
            - name: PUID
              value: "1000"
            - name: TZ
              value: Etc/UTC
          image: "ghcr.io/bentoml/openllm-ui-clojure:0.3.3"
          name: openllm-ui
          ports:

            - containerPort: 80
                    
          resources: {}
      restartPolicy: Always

      volumes:
                    
        - name: appdata
          hostPath:
            type: DirectoryOrCreate
            path: {{ .Values.userspace.appdata }}/openllm
                      
        - name: userdata
          hostPath:
            type: DirectoryOrCreate
            path: {{ .Values.userspace.data }}/openllm
                      
status: {}
---
apiVersion: v1
kind: Service
metadata:
  labels:
    io.kompose.service: openllm
  name: openllm
  namespace: {{ .Release.Namespace }}
spec:
  ports:

    - name: "3000"
      port: 3000
      targetPort: 3000
    - name: "80"
      port: 80
      targetPort: 80
  selector:
    io.kompose.service: openllm
status:
  loadBalancer: {}
                  