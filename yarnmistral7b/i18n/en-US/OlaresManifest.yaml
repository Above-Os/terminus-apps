metadata:
  title: Yarn Mistral 7B Q4
  description: A state-of-the-art language model for long context.
spec:
  fullDescription: "Nous-Yarn-Mistral-7b-128k is a state-of-the-art language model\
    \ for long context, further pretrained on long context data for 1500 steps using\
    \ the YaRN extension method.\n\nIt is an extension of Mistral-7B-v0.1 and supports\
    \ a 128k token context window.\n\nModel Name: Yarn Mistral 7B 128K\nModel Creator:\
    \ NousResearch\nModel Type: mistral\nQuantized by: TheBloke\nLibrary Name: transformers\n\
    \nBase model: NousResearch/Yarn-Mistral-7b-128k\n    \nDatasets:\n- emozilla/yarn-train-tokenized-16k-mistral\n"
  upgradeDescription: 'Update featuredImage

    '
