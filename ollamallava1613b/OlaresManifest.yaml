---
olaresManifest.version: '0.10.0'
olaresManifest.type: app
metadata:
  name: ollamallava1613b
  icon: https://app.cdn.olares.com/appstore/llm/ollama/multimodal/Llava-1.6-13b.png
  description: A novel end-to-end trained large multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding.
  appid: ollamallava1613b
  title: LLaVA 1.6 13B (Ollama)
  version: '1.1.6'
  categories:
    - AI
entrances:
  - name: api
    port: 8081
    host: api
    title: LLaVA 1.6 13B
    icon: https://app.cdn.olares.com/appstore/llm/ollama/multimodal/Llava-1.6-13b.png
    openMethod: default
  - authLevel: internal
    host: ollamaclient
    icon: https://app.cdn.olares.com/appstore/llm/ollama/multimodal/Llava-1.6-13b.png
    name: ollamaclient
    openMethod: default
    port: 8080
    title: LLaVA 1.6 API
    invisible: true
spec:
  versionName: 'llava:13b-v1.6-vicuna-q4_0'
  fullDescription: |
    ## IMPORTANT NOTE ##
    This is a shared app. Once installed by the Olares Admin, all users in the cluster can use it through reference app.

    ## MODEL OVERVIEW ##
    LLaVA is a multimodal model that combines a vision encoder and Vicuna for general-purpose visual and language understanding, achieving impressive chat capabilities mimicking spirits of the multimodal GPT-4.

    It is an auto-regressive language model, based on the transformer architecture. Base LLM: lmsys/vicuna-13b-v1.5

    # New in LLaVA 1.6:
    - Increasing the input image resolution to up to 4x more pixels, supporting 672x672, 336x1344, 1344x336 resolutions.
    - Better visual reasoning and OCR capability with an improved visual instruction tuning data mixture.
    - Better visual conversation for more scenarios, covering different applications.
    - Better world knowledge and logical reasoning.

  developer: haotian-liu
  website: https://llava-vl.github.io/
  sourceCode: https://github.com/haotian-liu/LLaVA
  submitter: Olares
  locale:
    - en-US
    - zh-CN
  license:
    - text: LLAMA 2 COMMUNITY LICENSE AGREEMENT
      url: https://ollama.com/library/llava:13b/blobs/41774062cd34

  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  limitedCpu: 6200m
  requiredCpu: 150m
  requiredDisk: 50Mi
  limitedDisk: 500Gi
  limitedMemory: 20Gi
  requiredMemory: 4200Mi
  requiredGpu: 0
  limitedGpu: 16Gi
  {{- else }}
  requiredMemory: 64Mi
  limitedMemory: 800Mi
  requiredDisk: 50Mi
  limitedDisk: 200Mi
  requiredCpu: 10m
  limitedCpu: 800m
  {{- end }}
  supportArch:
    - amd64
    - arm64

permission:
  appData: true
  appCache: true

options:
  apiTimeout: 0
  appScope:
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
    clusterScoped: true
    appRef:
      - ollamallava1613b
  {{- else }}
    clusterScoped: false
  {{- end }}
  dependencies:
    - name: olares
      version: '>=1.12.2-0'
      type: system
  {{- if and .Values.admin .Values.bfl.username (eq .Values.admin .Values.bfl.username) }}
  {{- else }}
    - name: ollamallava1613b
      type: application
      version: '>=1.1.3'
      mandatory: true
  {{- end }}

provider:
- name: ollamallava1613b
  entrance: ollamaclient
  paths: ["/*"]
  verbs: ["*"]