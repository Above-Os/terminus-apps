metadata:
  title: LLaMA-Factory
  description: Easy and Efficient LLM Fine-Tuning.
spec:
  fullDescription: "LlamaFactory, a unified framework that integrates a suite of cutting-edge\
    \ efficient training methods. It provides a solution for flexibly customizing\
    \ the fine-tuning of 100+ LLMs without the need for coding through the built-in\
    \ web UI LlamaBoard.\n\nFeatures  \n- Various models: LLaMA, LLaVA, Mistral, Mixtral-MoE,\
    \ Qwen, Yi, Gemma, Baichuan, ChatGLM, Phi, etc.\n- Integrated methods: (Continuous)\
    \ pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO,\
    \ KTO, ORPO, etc.\n- Scalable resources: 16-bit full-tuning, freeze-tuning, LoRA\
    \ and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.\n- Advanced algorithms:\
    \ GaLore, BAdam, Adam-mini, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+,\
    \ LoftQ, PiSSA and Agent tuning.\n- Practical tricks: FlashAttention-2, Unsloth,\
    \ RoPE scaling, NEFTune and rsLoRA.\n- Experiment monitors: LlamaBoard, TensorBoard,\
    \ Wandb, MLflow, etc.\n- Faster inference: OpenAI-style API, Gradio UI and CLI\
    \ with vLLM worker.\n"
  upgradeDescription: "# New features\nSupport contamination-free packing via the\
    \ neat_packing argument by @chuan298 in #4224\nSupport split evaluation via the\
    \ eval_dataset argument by @codemayq in #4691\nSupport HQQ/EETQ quantization via\
    \ the quantization_method argument by @hiyouga\nSupport ZeRO-3 when using BAdam\
    \ by @Ledzy in #4352\nSupport train on the last turn via the mask_history argument\
    \ by @aofengdaxia in #4878\nAdd NPU Dockerfile by @MengqingCao in #4355\nSupport\
    \ building FlashAttention2 in Dockerfile by @hzhaoy in #4461\nSupport batch_eval_metrics\
    \ at evaluation by @hiyouga\n\n# New models\nBase models\n- InternLM2.5-7B \n\
    - Gemma2 (9B/27B) \nInstruct/Chat models\n- TeleChat-1B-Chat by @hzhaoy in #4651\n\
    - InternLM2.5-7B-Chat\n- CodeGeeX4-9B-Chat \n- Gemma2-it (9B/27B)\n\n# Changes\n\
    Fix DPO cutoff len and deprecate reserved_label_len argument\nImprove loss function\
    \ for reward modeling\n\nAnd many bug fix\n\nFull release note at: https://github.com/hiyouga/LLaMA-Factory/releases/tag/v0.8.3\n"
